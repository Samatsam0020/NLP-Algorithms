{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd504f1a-0501-4a1f-b49b-bab4e26fb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f46b5-2004-4adf-80bc-4188a26438b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d165e6d7-d0d9-43ce-949a-f21328cf62ae",
   "metadata": {},
   "source": [
    "## 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac6f9240-83fb-4462-bb55-7f60979351f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(url, data_dir) : \n",
    "    os.makedirs(data_dir, exist_ok = True)\n",
    "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
    "\n",
    "    if not os.path.exists(file_path) : \n",
    "        print('downloading file...')\n",
    "        filename, _ = urlretrieve(url, file_path)\n",
    "    else :\n",
    "        print('File already exists')\n",
    "        \n",
    "    extract_path = os.path.join(data_dir, 'bbc')\n",
    "    if not os.path.exists(extract_path) : \n",
    "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf : \n",
    "            zipf.extractall(data_dir)\n",
    "\n",
    "    else : print(\"bbc-fulltext.zip has already been extracted\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733b50e9-066e-4619-835d-04cd9547428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
    "download_data(url, 'data_skipgram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896cb19-f1b0-40d3-90ba-adb17e1d617e",
   "metadata": {},
   "source": [
    "## 2. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cfa4335-3737-4cf0-8913-60b36ed6c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir) : \n",
    "    news_stories = []\n",
    "    print(\"reading files\")\n",
    "    for root, dirs, files in os.walk(data_dir) : \n",
    "        for fi, f in enumerate(files) : \n",
    "            if 'README' in f : \n",
    "                continue\n",
    "            print('.'*fi, f, end='\\r')\n",
    "            with open(os.path.join(root, f), encoding='latin-1') as f:\n",
    "                story = []\n",
    "                for row in f : \n",
    "                    story.append(row.strip())\n",
    "                story = ' '.join(story)\n",
    "                news_stories.append(story)\n",
    "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
    "    return news_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "991be719-4eef-4ec8-abde-17751e681c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading files\n",
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 226.txtt\n",
      "Detected 2225 stories\n"
     ]
    }
   ],
   "source": [
    "news_stories = read_data(os.path.join('data_skipgram', 'bbc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3478b0c-c62d-4818-992a-54fb1c2cc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865163 words found in the total news set\n",
      "Example words (start):  Franz Ferdinand's art school lesson  Scottish rock\n",
      "Example words (end):  rlake and all-woman singing group Destiny's Child.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
    "print('Example words (start): ',news_stories[0][:50])\n",
    "print('Example words (end): ',news_stories[-1][-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99717c4-25db-4a8a-815a-aa59034e7f7a",
   "metadata": {},
   "source": [
    "## 3. Preprocessing : \n",
    "+ Lowercase all the characters\n",
    "+ Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a233c6b-5777-4eb7-a91b-95233b5763ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=15000,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True,\n",
    "    split=' ',\n",
    "    oov_token='',\n",
    ")\n",
    "tokenizer.fit_on_texts(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67209b2e-13e6-466c-a5dc-4220bd952e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(tokenizer.word_index.items())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af2c35ca-065c-4fd3-a1be-4c5c48e7125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_sequences = tokenizer.texts_to_sequences(news_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79774c0b-2d6f-4e0d-9d16-d536d5f81b45",
   "metadata": {},
   "source": [
    "## 4. Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3a51678-72dc-447b-b12b-ee36f5c0bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_word_ids = news_sequences[0][:5]\n",
    "sample_phrase = ' '.join([tokenizer.index_word[wid] for wid in sample_word_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d31cc5ee-9819-4581-8532-111959c8bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1 # How many words to consider left and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e5173ff-feaf-44b4-9678-227572b691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    sequence = sample_word_ids,\n",
    "    vocabulary_size = n_vocab,\n",
    "    window_size = window_size,\n",
    "    negative_samples = 1.0,\n",
    "    shuffle = False,\n",
    "    categorical = False,\n",
    "    sampling_table = None,\n",
    "    seed = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "159f835a-38ba-4f82-a207-1ec5992c7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the unigram distribution as a prior for selecting negative context words\n",
    "inputs, labels = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    sample_word_ids,\n",
    "    vocabulary_size=len(tokenizer.word_index.items())+1,\n",
    "    window_size=window_size,\n",
    "    negative_samples=0, #We don't use negative_samples from this function\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6356da9e-3567-422c-9507-9bc0c3110ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = np.array(inputs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23cb8e9c-209a-4063-bd1b-153f403ed00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sampling_candidates, true_expected_count, sampled_expected_count = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=inputs[:1, 1:], # [b, 1] sized tensor\n",
    "    num_true=1, # number of true words per example\n",
    "    num_sampled=10,\n",
    "    unique=True,\n",
    "    range_max=n_vocab,\n",
    "    name=\"negative_sampling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d82c9-d5f8-4bab-bdbd-cb439a2087b8",
   "metadata": {},
   "source": [
    "## 5. Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c9dd4db-64a5-43d6-a259-c98726ad83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(n_vocab, sampling_factor=1e-05)\n",
    "\n",
    "def skip_gram_data_generator(sequences, window_size, batch_size, negative_samples, vocab_size, seed=None) :\n",
    "    rand_sequence_ids = np.arange(len(sequences))\n",
    "    np.random.shuffle(rand_sequence_ids)\n",
    "\n",
    "    #We generate positive skip grams\n",
    "    for si in rand_sequence_ids:\n",
    "        positive_skip_grams, _ =tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequences[si],\n",
    "            vocabulary_size=vocab_size,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0.0,\n",
    "            shuffle=False,\n",
    "            sampling_table=sampling_table,\n",
    "            seed=seed)\n",
    "\n",
    "    \n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    \n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "        context_class = tf.expand_dims(tf.constant([context_word],dtype=\"int64\"), 1)\n",
    "        \n",
    "        negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "        true_classes=context_class,\n",
    "        num_true=1,\n",
    "        num_sampled=negative_samples,\n",
    "        unique=True,\n",
    "        range_max=vocab_size,\n",
    "        name=\"negative_sampling\")\n",
    "        \n",
    "        # Build context and label vectors (for one target word)\n",
    "        context = tf.concat([tf.constant([context_word], dtype='int64'),negative_sampling_candidates],axis=0)\n",
    "        label = tf.constant([1] + [0]*negative_samples,dtype=\"int64\")\n",
    "        # Append each element from the training example to global\n",
    "        # lists.\n",
    "        targets.extend([target_word]*(negative_samples+1))\n",
    "\n",
    "        contexts.append(context)\n",
    "        labels.append(label)\n",
    "\n",
    "    contexts, targets, labels = np.concatenate(contexts),np.array(targets), np.concatenate(labels)\n",
    "    # If seed is not provided generate a random one\n",
    "    if not seed:\n",
    "        seed = int(random.randint(int(0), int(10e6)))\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(contexts)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(targets)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(labels)\n",
    "    for eg_id_start in range(0, contexts.shape[0], batch_size):\n",
    "        yield (targets[eg_id_start: min(eg_id_start+batch_size,\n",
    "        inputs.shape[0])],\n",
    "        contexts[eg_id_start: min(eg_id_start+batch_size,\n",
    "        inputs.shape[0])]\n",
    "        ), labels[eg_id_start: min(eg_id_start+batch_size,\n",
    "        inputs.shape[0])]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71470159-ea41-41ab-a1bd-94088f13e6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c247d66-f36c-4e84-9f91-42d6032a74f4",
   "metadata": {},
   "source": [
    "## 6. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "74f5da1b-1a84-4cf8-bf55-a258c703e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "batch_size = 4096 # Data points in a single batch\n",
    "embedding_size = 128 # Dimension of the embedding vector\n",
    "window_size=1\n",
    "negative_samples = 4\n",
    "epochs = 20\n",
    "valid_size = 16\n",
    "valid_window = 250\n",
    "np.random.seed(54321)\n",
    "random.seed(54321)\n",
    "\n",
    "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
    "valid_term_ids = np.append(\n",
    "valid_term_ids, random.sample(range(1000, 1000+valid_window),\n",
    "valid_size),\n",
    "axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2dc58101-b1ee-4d87-821e-81b1de3718eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "33c5767f-a5f8-42e3-a1d9-921dbf98318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs - skipgrams() function outputs target, context in that order\n",
    "input_1 = tf.keras.layers.Input(shape=(), name='target')\n",
    "input_2 = tf.keras.layers.Input(shape=(), name='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b09ffd5-2839-4d3e-af67-62bdf5a8acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two embeddings layers are used one for the context and one for the target\n",
    "target_embedding_layer = tf.keras.layers.Embedding(input_dim=n_vocab, output_dim=embedding_size,name='target_embedding')\n",
    "context_embedding_layer = tf.keras.layers.Embedding(input_dim=n_vocab, output_dim=embedding_size,name='context_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5f2abfbc-66b4-45a6-b95b-ddcd007b9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup outputs of the embedding layers\n",
    "target_out = target_embedding_layer(input_1)\n",
    "context_out = context_embedding_layer(input_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ea717a9-c6b7-4ea6-b8ce-5dec6daeb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the dot product between the two\n",
    "out = tf.keras.layers.Dot(axes=-1)([context_out, target_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3b7e9f83-592a-49cd-8620-8752f83c84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "skip_gram_model = tf.keras.models.Model(inputs=[input_1, input_2],\n",
    "outputs=out, name='skip_gram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2d11290e-b92f-4b1d-936a-12c675f5dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "skip_gram_model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d0dfa6a0-2e53-474a-9e61-47a29024473d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"skip_gram_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"skip_gram_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ context_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,142,208</span> │ context[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target_embedding    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,142,208</span> │ target[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ context_embeddin… │\n",
       "│                     │                   │            │ target_embedding… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ context             │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ context_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m4,142,208\u001b[0m │ context[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ target_embedding    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m4,142,208\u001b[0m │ target[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ context_embeddin… │\n",
       "│                     │                   │            │ target_embedding… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,284,416</span> (31.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,284,416\u001b[0m (31.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,284,416</span> (31.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,284,416\u001b[0m (31.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skip_gram_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94cc8b4-0da0-45cd-a4d0-dc1fe3f64a4c",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9dba57bd-971d-40d9-a363-0106880ab9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
    "        self.valid_term_ids = valid_term_ids\n",
    "        self.model_with_embeddings = model_with_embeddings\n",
    "        self.tokenizer = tokenizer\n",
    "        super().__init__()\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\" Validation logic \"\"\"\n",
    "        # We will use context embeddings to get the most similar words\n",
    "        # Other strategies include: using target embeddings, mean\n",
    "        # embeddings after avaraging context/target\n",
    "        \n",
    "        embedding_weights =self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
    "        \n",
    "        normalized_embeddings = embedding_weights /np.sqrt(np.sum(embedding_weights**2, axis=1, keepdims=True))\n",
    "        # Get the embeddings corresponding to valid_term_ids\n",
    "        valid_embeddings = normalized_embeddings[self.valid_term_ids,:]\n",
    "        \n",
    "        # Compute the similarity between valid_term_ids and all the embeddings\n",
    "        # V x d (d x D) => V x D\n",
    "        \n",
    "        top_k = 5 # Top k items will be displayed\n",
    "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
    "        # Invert similarity matrix to negative\n",
    "        # Ignore the first one because that would be the same word as the probe word\n",
    "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1:top_k+1]\n",
    "        \n",
    "        # Print the output\n",
    "        for i, term_id in enumerate(valid_term_ids):\n",
    "            similar_word_str = ', '.join([self.tokenizer.index_word[j]\n",
    "            for j in similarity_top_k[i, :] if j > 1])\n",
    "            print(f\"{self.tokenizer.index_word[term_id]}:{similar_word_str }\")\n",
    "            \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "655f004a-0dd4-4264-9011-ba075bf49a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram_validation_callback = ValidationCallback(valid_term_ids, skip_gram_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5211afd1-fa08-4755-963f-88e5b6f2cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "\n",
    "for ei in range(epochs):\n",
    "    print(f\"Epoch: {ei+1}/{epochs} started\")\n",
    "    news_skip_gram_gen = skip_gram_data_generator(news_sequences, window_size, batch_size, negative_samples,n_vocab)\n",
    "    \n",
    "    skip_gram_model.fit(news_skip_gram_gen, epochs=1,callbacks=skipgram_validation_callback,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
